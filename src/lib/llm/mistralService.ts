export interface LLMMessage {
  role: 'user' | 'assistant' | 'system';
  content: string;
}

export class MultiverseAIService {
  public models = {
    free: {
      'nebula-mistral': 'mistral-large-latest'
    },
    premium: {
      'stellar-coder': 'Qwen/Qwen2.5-Coder-32B-Instruct',
      'cosmos-vision': 'Qwen/Qwen2-VL-72B-Instruct'
    }
  };

  constructor() {
    const apiKey = import.meta.env.VITE_MISTRAL_API_KEY;
    if (!apiKey) {
      console.warn('Mistral API key is not configured');
    }
  }

  async generateStream(messages: LLMMessage[], modelId: string, onChunk: (chunk: string) => void) {
    const modelMap = { ...this.models.free, ...this.models.premium };
    const modelName = modelMap[modelId];

    if (!modelName) {
      throw new Error(`Model ${modelId} not found`);
    }

    try {
      // Simulate AI response for now
      const response = `// Generated by ${modelId}\n// This is a simulated response\n// Your web app code would appear here\n\nfunction App() {\n  return (\n    <div>\n      <h1>Your Generated Web App</h1>\n      <p>Built with Multiverse AI</p>\n    </div>\n  );\n}`;
      
      // Stream the response character by character for realism
      for (let i = 0; i < response.length; i++) {
        await new Promise(resolve => setTimeout(resolve, 10));
        onChunk(response[i]);
      }
    } catch (error) {
      console.error(`Error with model ${modelId}:`, error);
      onChunk(`\n\nError: ${error}. Please check your API keys.`);
    }
  }

  async generateWithAllModels(messages: LLMMessage[], onProgress: (model: string, chunk: string) => void) {
    const allModels = Object.keys({ ...this.models.free, ...this.models.premium });
    
    const promises = allModels.map(modelId => 
      this.generateStream(messages, modelId, (chunk) => {
        onProgress(modelId, chunk);
      }).catch(error => {
        console.error(`Model ${modelId} failed:`, error);
        onProgress(modelId, `\nError: ${error}`);
      })
    );

    await Promise.allSettled(promises);
  }
}
